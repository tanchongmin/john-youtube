{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec595496-de08-4232-982e-8c88eb3f9aef",
   "metadata": {},
   "source": [
    "# Multimodal Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd629049-33c5-483f-80a4-2996d0b026f3",
   "metadata": {},
   "source": [
    "8 Jul 2025\n",
    "- Added SHA256 hashing for key for hashing image/text query and storing of user query efficiently\n",
    "- Change input type to \"search_query\" instead of \"multimodal\" or \"image\", as \"search_query\" can handle hybrid input types\n",
    "\n",
    "Created by John Tan Chong Min, 7 Jul 2025\n",
    "- This does multimodal query with image/text as hybrid inputs, with possibility of negative filters as well\n",
    "- Modify your dataset with the folder name PARENT (default is \"Fruits\"), and all subfolders of that folder will be available for selection for filtering\n",
    "\n",
    "This is the initial vibe coding chat for multimodal query: https://chatgpt.com/share/686cddad-036c-8006-befa-7150e31f17f7\n",
    "\n",
    "### Dataset used: \n",
    "- https://www.kaggle.com/datasets/shreyapmaher/fruits-dataset-images\n",
    "- Download and put into a folder Fruits in same directory as this Jupyter Notebook\n",
    "\n",
    "File structure\n",
    "+ Current Directory\n",
    "    + Fruits (folder)\n",
    "    + .env (containing COHERE_API_KEY inside)\n",
    "    + embeddings.db (automatically generated with the sqlite3 in this code)\n",
    "    + Multimodal_Index.ipynb (this notebook)\n",
    "  \n",
    "### Multimodal Embedding Used: \n",
    "- Cohere Embed v4 https://cohere.com/blog/embed-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ec3039-8e0f-4194-a3e3-35fc51424f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install --quiet cohere python-dotenv numpy pillow gradio\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import sqlite3\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import cohere\n",
    "from io import BytesIO\n",
    "from PIL import Image as PILImage\n",
    "import gradio as gr\n",
    "\n",
    "# ─── Configuration ──────────────────────────────────────────────────────────────\n",
    "MODEL = \"embed-v4.0\"\n",
    "PARENT = \"Fruits\"\n",
    "NUM_FILES_PER_FOLDER = 10\n",
    "\n",
    "# Load Cohere API key from .env\n",
    "dotenv_path = Path('.') / '.env'\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path)\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "if not COHERE_API_KEY:\n",
    "    raise RuntimeError(\"Please set COHERE_API_KEY in your .env file.\")\n",
    "\n",
    "co = cohere.ClientV2(api_key=COHERE_API_KEY)\n",
    "\n",
    "# ─── Helper Functions ───────────────────────────────────────────────────────────\n",
    "def load_image_as_data_url(path: Path) -> str:\n",
    "    \"\"\"Read an image file and return a data URL (base64-encoded).\"\"\"\n",
    "    mime = \"image/png\" if path.suffix.lower() == \".png\" else \"image/jpeg\"\n",
    "    raw = path.read_bytes()\n",
    "    b64 = base64.b64encode(raw).decode(\"utf-8\")\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "def pad_to_square(img: PILImage.Image, fill_color=(255, 255, 255)) -> PILImage.Image:\n",
    "    \"\"\"Pad a PIL image to a square with a white background.\"\"\"\n",
    "    w, h = img.size\n",
    "    m    = max(w, h)\n",
    "    new  = PILImage.new('RGB', (m, m), fill_color)\n",
    "    new.paste(img, ((m - w) // 2, (m - h) // 2))\n",
    "    return new\n",
    "\n",
    "def pad_images(files):\n",
    "    \"\"\"Apply square-padding to a list of image files for gallery preview.\"\"\"\n",
    "    if not files:\n",
    "        return []\n",
    "    padded = []\n",
    "    for f in files:\n",
    "        img = PILImage.open(f)\n",
    "        padded.append(pad_to_square(img))\n",
    "    return padded\n",
    "\n",
    "# ─── Embedding Cache (SQLite) ─────────────────────────────────────────────────\n",
    "conn = sqlite3.connect(\"embeddings.db\", check_same_thread=False)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS embeddings (\n",
    "        key           TEXT PRIMARY KEY,\n",
    "        vector        BLOB,\n",
    "        model_version TEXT\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "def get_or_create_embedding(raw_key: str, inputs: list[dict], input_type: str, skip_cache: bool=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Fetch an embedding from cache or compute it via Cohere.\n",
    "    Caches result in SQLite for reuse, using a SHA-256 of the raw key.\n",
    "    \"\"\"\n",
    "    # Compute cache key as SHA-256 hex digest\n",
    "    hashed_key = hashlib.sha256(raw_key.encode('utf-8')).hexdigest()\n",
    "\n",
    "    if not skip_cache:\n",
    "        cur.execute(\n",
    "            \"SELECT vector FROM embeddings WHERE key=? AND model_version=?\",\n",
    "            (hashed_key, MODEL)\n",
    "        )\n",
    "        row = cur.fetchone()\n",
    "        if row:\n",
    "            return np.frombuffer(row[0], dtype=np.float32)\n",
    "\n",
    "    resp = co.embed(\n",
    "        model=MODEL,\n",
    "        inputs=inputs,\n",
    "        input_type=input_type,\n",
    "        embedding_types=[\"float\"],\n",
    "        output_dimension=1536\n",
    "    )\n",
    "    emb = np.array(resp.embeddings.float, dtype=np.float32)[0]\n",
    "\n",
    "    if not skip_cache:\n",
    "        cur.execute(\n",
    "            \"INSERT OR REPLACE INTO embeddings (key, vector, model_version) VALUES (?, ?, ?)\",\n",
    "            (hashed_key, emb.tobytes(), MODEL)\n",
    "        )\n",
    "        conn.commit()\n",
    "\n",
    "    return emb\n",
    "\n",
    "# ─── Pre-index Dataset Images ──────────────────────────────────────────────────\n",
    "exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "paths = []\n",
    "\n",
    "for sub in sorted(Path(PARENT).iterdir()):\n",
    "    if sub.is_dir():\n",
    "        for p in sorted(sub.glob(\"*.*\"))[:NUM_FILES_PER_FOLDER]:\n",
    "            if p.suffix.lower() in exts:\n",
    "                paths.append(p)\n",
    "\n",
    "# Compute and normalize embeddings for each image\n",
    "def _build_index_embeddings(paths):\n",
    "    embs = []\n",
    "    for p in paths:\n",
    "        key = f\"img:{p.relative_to(PARENT)}\"\n",
    "        url = load_image_as_data_url(p)\n",
    "        inp = [{\"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": url}}]}]\n",
    "        emb = get_or_create_embedding(key, inp, \"search_query\")\n",
    "        embs.append(emb)\n",
    "    embs = np.vstack(embs)\n",
    "    norms = np.linalg.norm(embs, axis=1, keepdims=True)\n",
    "    return embs / (norms + 1e-12)\n",
    "\n",
    "image_embs = _build_index_embeddings(paths)\n",
    "\n",
    "# Subfolder filter defaults\n",
    "subfolders      = [d.name for d in sorted(Path(PARENT).iterdir()) if d.is_dir()]\n",
    "default_folders = subfolders.copy()\n",
    "\n",
    "# ─── Search Function ────────────────────────────────────────────────────────────\n",
    "def search(\n",
    "    pos_text, pos_files,\n",
    "    neg_text, neg_files,\n",
    "    top_k, folders\n",
    "):\n",
    "    # Parse inputs\n",
    "    texts_pos = [t.strip() for t in pos_text.splitlines() if t.strip()]\n",
    "    texts_neg = [t.strip() for t in neg_text.splitlines() if t.strip()]\n",
    "    pos_imgs   = [PILImage.open(fp) for fp in (pos_files or [])]\n",
    "    neg_imgs   = [PILImage.open(fn) for fn in (neg_files or [])]\n",
    "\n",
    "    if not texts_pos and not pos_imgs:\n",
    "        raise gr.Error(\"Provide at least one positive text or image file.\")\n",
    "\n",
    "    def embed_items(texts, images, skip_cache=False):\n",
    "        \"\"\"Embed a mix of text + images into a single vector.\"\"\"\n",
    "        inputs = []\n",
    "        key_parts = []\n",
    "        # Text inputs\n",
    "        for t in texts:\n",
    "            inputs.append({\"type\": \"text\", \"text\": t})\n",
    "            key_parts.append(t)\n",
    "        # Image inputs (serialize to PNG)\n",
    "        for im in images:\n",
    "            buf = BytesIO()\n",
    "            im.save(buf, format=\"PNG\")\n",
    "            b64 = base64.b64encode(buf.getvalue()).decode()\n",
    "            inputs.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{b64}\"}\n",
    "            })\n",
    "            key_parts.append(b64)\n",
    "\n",
    "        mode = \"search_query\"\n",
    "        raw_key = \"||\".join(key_parts)\n",
    "        emb = get_or_create_embedding(raw_key, [{\"content\": inputs}], mode, skip_cache)\n",
    "        return emb / np.linalg.norm(emb)\n",
    "\n",
    "    # Positive embedding & ranking\n",
    "    emb_pos   = embed_items(texts_pos, pos_imgs)\n",
    "    valid_idx = [i for i, p in enumerate(paths) if p.parent.name in folders]\n",
    "    pos_sims  = image_embs.dot(emb_pos)\n",
    "    ranked    = sorted(valid_idx, key=lambda i: -pos_sims[i])\n",
    "\n",
    "    # Optional negative filtering\n",
    "    if texts_neg or neg_imgs:\n",
    "        emb_neg = embed_items(texts_neg, neg_imgs)\n",
    "        neg_sims = image_embs.dot(emb_neg)\n",
    "        exclude = set(sorted(valid_idx, key=lambda i: -neg_sims[i])[:top_k])\n",
    "        ranked = [i for i in ranked if i not in exclude]\n",
    "\n",
    "    # Return top-k results\n",
    "    return [\n",
    "        (str(paths[i]), f\"{paths[i].relative_to(PARENT)} ({pos_sims[i]:.4f})\")\n",
    "        for i in ranked[:top_k]\n",
    "    ]\n",
    "\n",
    "# ─── CSS for Tight Single-Row Previews ─────────────────────────────────────────\n",
    "css = \"\"\"\n",
    "#pos_preview {\n",
    "    display: grid !important;\n",
    "    grid-auto-flow: column !important;\n",
    "    grid-auto-columns: auto !important;\n",
    "    grid-template-rows: 1fr !important;\n",
    "    gap: 0 !important;\n",
    "    overflow-x: auto !important;\n",
    "    max-height: 100px !important;\n",
    "}\n",
    "#neg_preview {\n",
    "    display: grid !important;\n",
    "    grid-auto-flow: column !important;\n",
    "    grid-auto-columns: auto !important;\n",
    "    grid-template-rows: 1fr !important;\n",
    "    gap: 0 !important;\n",
    "    overflow-x: auto !important;\n",
    "    max-height: 100px !important;\n",
    "}\n",
    "#gallery {\n",
    "    display: grid !important;\n",
    "    grid-auto-flow: column !important;\n",
    "    grid-auto-columns: auto !important;\n",
    "    grid-template-rows: 1fr !important;\n",
    "    gap: 0 !important;\n",
    "    overflow-x: auto !important;\n",
    "    max-height: 100px !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# ─── Build Gradio UI ───────────────────────────────────────────────────────────\n",
    "demo = gr.Blocks(css=css)\n",
    "\n",
    "with demo:\n",
    "    gr.Markdown(\"### Semantic Image Search - Text & Image\")\n",
    "\n",
    "    with gr.Row():\n",
    "        pos_text   = gr.Textbox(label=\"Positive Text Queries (one per line)\", lines=3)\n",
    "        pos_files  = gr.Files(file_types=[\".jpg\", \".jpeg\", \".png\"],\n",
    "                              label=\"Positive Image Files\")\n",
    "        pos_preview = gr.Gallery(label=\"Positive Previews\",\n",
    "                                 columns=10,\n",
    "                                 elem_id=\"pos_preview\")\n",
    "\n",
    "    pos_files.change(pad_images, inputs=pos_files, outputs=pos_preview)\n",
    "\n",
    "    with gr.Row():\n",
    "        neg_text   = gr.Textbox(label=\"Negative Text Queries (one per line)\", lines=3)\n",
    "        neg_files  = gr.Files(file_types=[\".jpg\", \".jpeg\", \".png\"],\n",
    "                              label=\"Negative Image Files\")\n",
    "        neg_preview = gr.Gallery(label=\"Negative Previews\",\n",
    "                                 columns=10,\n",
    "                                 elem_id=\"neg_preview\")\n",
    "\n",
    "    neg_files.change(pad_images, inputs=neg_files, outputs=neg_preview)\n",
    "\n",
    "    top_k     = gr.Slider(1, 20, value=5, step=1, label=\"Top K Results\")\n",
    "    folders   = gr.CheckboxGroup(choices=subfolders,\n",
    "                                value=default_folders,\n",
    "                                label=\"Filter Subfolders (optional)\")\n",
    "    search_btn = gr.Button(\"Search\")\n",
    "\n",
    "    with gr.Row():\n",
    "        gallery = gr.Gallery(label=\"Results\", columns=5)\n",
    "        search_btn.click(fn=search,\n",
    "                         inputs=[pos_text, pos_files, neg_text, neg_files, top_k, folders],\n",
    "                         outputs=gallery)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo.launch(debug=True, show_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2953719-adfb-45d2-aeb7-a69c3e1a1e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
